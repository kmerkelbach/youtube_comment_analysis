{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd68cc20-4983-44a7-b931-27cf92fc6113",
   "metadata": {},
   "source": [
    "# Youtube Comments Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bea4d9-e984-4607-a401-f9a89ee8855a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3d9793-14fe-41b6-88b4-3b63c54cec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import namedtuple, defaultdict\n",
    "from datetime import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json\n",
    "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN, HDBSCAN, OPTICS\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial import distance\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cfeb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# My own modules\n",
    "from util.string_utils import split_text_if_long\n",
    "from models.text_models import TextModelManager\n",
    "from models.computations import ClassificationType\n",
    "from models.math_funcs import cos_sim\n",
    "from models.llm_api import LLM\n",
    "from api.youtube_api import YoutubeAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b909081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s.%(msecs)03d - %(name)s - %(levelname)s - %(message)s',  # Define the log format with milliseconds\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Define the date and time format without milliseconds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e5103-a2f5-4dbb-8f20-65cfaf3cc7eb",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec47aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 10:24:26.292 - models.text_models - INFO - Instantiating TextModelManager.\n"
     ]
    }
   ],
   "source": [
    "# Initialize classification models\n",
    "text_model_manager = TextModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dca2b-1349-4677-a502-4ee1d719fadf",
   "metadata": {},
   "source": [
    "## Set up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ca201e-fb9d-43dd-9507-bdfafc6e439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf2fc6-a49a-4ace-9bca-249703491ef4",
   "metadata": {},
   "source": [
    "## Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a4f8cc-e459-4cf6-b584-2c574310d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 10:24:26.342 - googleapiclient.discovery_cache - INFO - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "youtube = YoutubeAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f56fdad-bc02-4a3a-9dbb-2ab2514d677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_video_test_id_tomato = \"9WQnap-UAiQ\"\n",
    "yt_video_test_id_10k_comments = \"2-XxbdR3Nik\"\n",
    "yt_video_test_id_4500_comments = \"-ih0B9yn32Q\"\n",
    "yt_video_test_id_4k_comments_beard_meets_schnitzel = \"qPd9qPUR2_U\"\n",
    "yt_video_test_id_2000_comments = \"rX2tK-qSVpk\"\n",
    "yt_video_test_id_700_comments = \"VCXqELB3UPg\"\n",
    "yt_video_test_id_300_comments = \"yQqJafC7xv0\"\n",
    "yt_video_test_id_25_comments = \"kiF0wgM8zGc\"\n",
    "yt_video_test_id_50_comments = \"LHQMIuzjl48\"\n",
    "\n",
    "yt_video_id = yt_video_test_id_50_comments\n",
    "youtube.set_current_video(yt_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bccbd94-3da0-4d75-8460-79772a19c6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perfect OFFICE Custom Keyboard!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube.get_title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e329998-2c17-45a9-bae5-87a9128d79d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lewis Toh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube.get_creator_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f990f-ba39-450b-b720-afa3d270c243",
   "metadata": {},
   "source": [
    "## Comment Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6a749f-e4b1-4286-9d96-6b20d2eb4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 10:24:26.525 - api.youtube_api - INFO - Starting raw comment retrieval.\n",
      "2024-07-14 10:24:26.629 - api.youtube_api - INFO - Received 31 top-level comments.\n",
      "2024-07-14 10:24:26.630 - api.youtube_api - INFO - Finished raw comment retrieval of 31 top-level comments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comments retrieval for video ID LHQMIuzjl48 ('Perfect OFFICE Custom Keyboard!')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting replies for comments with missing replies ...: 100%|██████████| 31/31 [00:00<00:00, 204439.35it/s]\n",
      "Converting comments to our own class ...: 100%|██████████| 31/31 [00:00<00:00, 4255.53it/s]\n",
      "Deduplicating comments ...: 100%|██████████| 31/31 [00:00<00:00, 13104.56it/s]\n"
     ]
    }
   ],
   "source": [
    "comments = youtube.get_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "884dd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.sort(key=lambda comm: comm.num_replies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e69108d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Comment(@LewisToh @ 2024-02-02T13:57:30+00:00: 'oh shit LOL') (5 likes; 0 replies),\n",
       " Comment(@KeebClack @ 2024-02-02T13:59:26+00:00: 'lol​@@LewisToh') (0 likes; 0 replies),\n",
       " Comment(@canonwhale @ 2024-02-02T18:27:01+00:00: 'Just goes to show you don’t need to know what that is to have 78.3k followers!') (0 likes; 0 replies),\n",
       " Comment(@VladK-1 @ 2024-02-17T01:10:39+00:00: '@@canonwhale82,2 now! and one more subscriber!') (0 likes; 0 replies)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[-1].replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e16081",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Stop here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop here\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Stop here"
     ]
    }
   ],
   "source": [
    "assert False, \"Stop here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3055ba-1bc2-4d5a-8373-daa2560086d7",
   "metadata": {},
   "source": [
    "## Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3761314-f2e4-4d28-87ab-d5d18189ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_classes(comments: List[Comment], classi_type: ClassificationType, take_argmax=False):\n",
    "    res = []\n",
    "    likes = []\n",
    "    for comm in tqdm(comments, desc=f\"Determining computated facts ({classi_type.name}; argmax={take_argmax}) ...\"):\n",
    "        comp = dict(comm.get_classification(classi_type))\n",
    "\n",
    "        # If requested, set the maximum-probability class to the sum of probabilities and the rest to 0.0\n",
    "        if take_argmax:\n",
    "            max_idx = np.argmax(comp.values())\n",
    "            prob_sum = sum(comp.values())\n",
    "            \n",
    "            for idx, k in enumerate(comp.keys()):\n",
    "                if idx == max_idx:\n",
    "                    comp[k] = prob_sum\n",
    "                else:\n",
    "                    comp[k] = 0.0\n",
    "            \n",
    "        res.append(comp)\n",
    "        likes.append(comm.likes)\n",
    "\n",
    "    # Find out like-weighted score for each class\n",
    "    classes = res[0].keys()\n",
    "    stats = {}\n",
    "    for cl in classes:\n",
    "        # Get raw scores\n",
    "        class_scores = np.array([scores[cl] for scores in res])\n",
    "\n",
    "        # Weight each score by likes\n",
    "        class_scores = np.multiply(class_scores, np.array(likes))\n",
    "\n",
    "        # Find out mean score\n",
    "        total_likes = np.sum(likes)\n",
    "        mean_score = np.sum(class_scores) / total_likes\n",
    "\n",
    "        # Save result\n",
    "        stats[cl] = mean_score\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8088e25-5041-4560-bb22-803891f3aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_comments(comments):\n",
    "    res = []\n",
    "    for comm in comments:\n",
    "        # Add comment itself\n",
    "        res.append(comm)\n",
    "\n",
    "        # Add its replies\n",
    "        res += flatten_comments(comm.replies)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af724c-dd09-4d7c-a08d-21ccce4c1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_classification_analysis(comments: List[Comment], classi_type: ClassificationType):\n",
    "    for argmax_label, argmax_bool in [(\"Soft\", False), (\"Hard\", True)]:\n",
    "        mean_clss = find_mean_classes(comments, classi_type, take_argmax=argmax_bool)\n",
    "    \n",
    "        print(f\"({argmax_label}) Mean {classi_type.name} for {len(comments)} comments:\")\n",
    "        for cl, mc in mean_clss.items():\n",
    "            print(f\"{cl}:\".ljust(20) + f\"{100 * mc:0.2f}%\".rjust(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf469b-42d6-41f8-b435-02ad15fa34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extreme_class_examples(comments: List[Comment], classi_type: ClassificationType, num_shown : int = 10):\n",
    "    for cl in comments[0].get_classification(classi_type).keys():\n",
    "        print(f\"{num_shown} most {cl} comments: \")\n",
    "        display(sorted(comments, key=lambda comm: comm.get_classification(classi_type)[cl], reverse=True)[:num_shown])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1e22f2-f905-4850-aad4-d9db7cfd0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes_to_arr(comm: Comment, classi_type: ClassificationType):\n",
    "    return np.array(list(comm.get_classification(classi_type).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7aed6-e2f7-48d8-af0d-b10eb6aade71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_disagreement_in_replies(toplevel_comments: List[Comment], classi_type: ClassificationType):\n",
    "    df_rows = []\n",
    "    for comm in toplevel_comments:\n",
    "        # Skip if there are no replies\n",
    "        if len(comm.replies) == 0:\n",
    "            continue\n",
    "    \n",
    "        # Consider the first reply\n",
    "        repl = comm.replies[0]\n",
    "    \n",
    "        # Find out sum of differences between sentiment of comment and reply\n",
    "        diffs = np.sum(np.power(np.abs(classes_to_arr(comm, classi_type) - classes_to_arr(repl, classi_type)), 2))\n",
    "        \n",
    "        df_rows.append({\"comment\": comm.text, \"reply\": repl.text, \"difference\": diffs})\n",
    "    \n",
    "    df = pd.DataFrame(df_rows)\n",
    "    df = df.sort_values(by=\"difference\", ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b745c68-0ec3-4c7b-b04c-abfbb66fe98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_analysis(comments: List[Comment], classi_type: ClassificationType):\n",
    "    # Mean classes\n",
    "    for comment_label, comment_list in [(\"top-level\", comments), (\"all\", flatten_comments(comments))]:\n",
    "        print(f\"Classification ({classi_type.name}) analysis for {comment_label} comments:\")\n",
    "        mean_classification_analysis(comment_list, classi_type)\n",
    "        print()\n",
    "    \n",
    "    # Extreme examples\n",
    "    show_extreme_class_examples(comments, classi_type)\n",
    "\n",
    "    # Disagreement in replies\n",
    "    print(f\"Disagreement in replies for {classi_type.name} classes:\")\n",
    "    display(class_disagreement_in_replies(comments, classi_type).iloc[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e20391-b9c7-4807-b095-ddd0c04b9835",
   "metadata": {},
   "source": [
    "### Video Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b345a3-fe95-4936-92b2-0451efc0b50d",
   "metadata": {},
   "source": [
    "Some of the models only work for English. We assume that the comments will be in the language of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0621a-bc47-4557-8066-8d95a393f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_lang(video_info):\n",
    "    return video_info[field_items][0][field_sni][field_audio_lang].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c97b77-0dc8-4689-8762-574bc2224606",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = get_video_info(yt_video_id)\n",
    "video_lang = get_video_lang(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976d709-e235-4543-94dc-53681775fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Video titled '{get_title(info)}' has language: {video_lang}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b9ce5-5da2-45e3-b392-8058e2190fa7",
   "metadata": {},
   "source": [
    "### Sentiment + Meaning\n",
    "What are positive comments saying vs. what are negative comments saying?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3e1be-aa4d-4f34-877c-98516ef96bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comments (for testing)\n",
    "comments = get_comments(yt_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee9fb8-0222-4b33-9b66-a8f640d48aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_class(computation_result):\n",
    "    max_idx = np.argmax(computation_result.values())\n",
    "    return list(computation_result.keys())[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac4cab-52d5-46c1-8e1d-1fce2c3ec343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group comments by sentiment\n",
    "sentiment_groups = defaultdict(list)\n",
    "\n",
    "for comm in tqdm(comments, \"Grouping by sentiment ...\"):\n",
    "    comp = comm.get_classification(ClassificationType.Sentiment)\n",
    "    sen = get_max_class(comp)\n",
    "    magnitude = comp[sen]\n",
    "    if magnitude > 0.75:\n",
    "        sentiment_groups[sen].append(comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf0b22-1b8d-4605-b048-5f394e55010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen, sen_comments in sentiment_groups.items():\n",
    "    print(f\"- {len(sen_comments)} {sen} comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201ab13-1767-4763-91bf-b3112bcfa5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show word clouds\n",
    "for sen, sen_comments in sentiment_groups.items():\n",
    "    print(sen)\n",
    "    wc = wordcloud.WordCloud()\n",
    "    wc.generate(\" \".join([comm.text for comm in sen_comments]))\n",
    "    display(wc.to_image())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b57bef-440d-4817-b938-1ae9afc34db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_newline = \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86466ab9-47d4-4359-bee4-0e89f8315687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_line(text, max_length):\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length]\n",
    "        text = \" \".join(text.split()[:-1])\n",
    "        text += \"...\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f6b78-d57f-4a88-a4a9-e2ec0495759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_comments(comments, max_chars_per_comment=200, max_comment_chars_shown=2500):\n",
    "    comments = list(comments)\n",
    "    comm_lines = []\n",
    "    random.shuffle(comments)\n",
    "    idx = 0\n",
    "    while (sum(len(l) for l in comm_lines) < max_comment_chars_shown) and (idx < len(comments)):\n",
    "        comm = comments[idx]\n",
    "        text = comm.text\n",
    "        while double_newline in text:\n",
    "            text = text.replace(double_newline, \"\\n\")\n",
    "        if len(text) > max_chars_per_comment:\n",
    "            text = truncate_line(text, max_chars_per_comment)\n",
    "        comm_lines.append(f\"- \\\"{text}\\\"\")\n",
    "        idx += 1\n",
    "    return comm_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960f50f-dc6c-4925-97bc-e9425e1dcd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_extract_statements(video_info, comments: List[Comment]):\n",
    "    title = get_title(video_info)\n",
    "    lines = [f\"You are a professional YouTube comment analyst. Given a video title and some comments, extract statements from the comments.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    \n",
    "    lines.append(\"\\nSample from the comments:\")\n",
    "    comm_lines = sample_from_comments(comments)\n",
    "    lines += comm_lines\n",
    "\n",
    "    lines.append(\"\\nExtract 5 statements voiced in the comments. A statement should be a simple thought expressed by many comments, e.g., \\\"The video was well-edited.\\\" or \\\"I disagree with the premise of the video.\\\". Phrase each statement in a way it could be uttered by a viewer of the video. \" \\\n",
    "                 \"Do not explain any of the statements you extract. \" \\\n",
    "                 \"There is no need to repeat the video title in your assessment.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb7698-7fa3-44c7-ad95-8757a4981742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_extract_statements(raw):\n",
    "    lines = raw.split(\"\\n\")\n",
    "    lines = [l for l in lines if len(l) > 0]  # remove blank lines\n",
    "\n",
    "    # Look for enumeration at the start of the line (keep lines such as those starting with \"4. \", \"15.\", \"- \", or \"• \")\n",
    "    matched = [(l, re.search(\"^(\\d+\\.|-|•|\\*)\", l)) for l in lines]\n",
    "    matched = [(l, m) for (l, m) in matched if m is not None]\n",
    "\n",
    "    # Remove enumeration at the start of the line\n",
    "    lines = [l[m.span()[-1]:] for (l, m) in matched]\n",
    "\n",
    "    # Strip lined\n",
    "    lines = [l.strip() for l in lines]\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a69b4-4256-4fbc-a9ff-2f4a74f3a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract statements from positive and negative comments\n",
    "comment_statements = {}\n",
    "msg_str = \"\"\n",
    "for sen, sen_comments in sentiment_groups.items():\n",
    "    msg_str += f\" {sen.capitalize()} Sentiment Comments \".center(50, \"-\")\n",
    "    msg_str += \"\\n\"\n",
    "\n",
    "    # Construct the LLM prompt and summarize the comments\n",
    "    prompt = build_prompt_extract_statements(info, sen_comments)\n",
    "    res_raw = llm.chat(prompt)\n",
    "    res_lines = post_process_extract_statements(res_raw)\n",
    "    comment_statements[sen] = res_lines\n",
    "    msg_str += \"\\n\".join([f\"- {l}\" for l in res_lines]) + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72a1c2-ccf2-4725-b717-c8a3c835f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3e80b-9287-4d66-bda4-b208d6d65b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing, reduce the number of statements\n",
    "comment_statements = {kind: [statements[idx] for idx in np.random.choice(np.arange(len(statements)), size=min(len(statements), 2), replace=False)] for (kind, statements) in comment_statements.items()}\n",
    "comment_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca3232-b303-47a7-8a6a-3d6517349de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_prompt_settings = {\n",
    "    \"min\": -5,\n",
    "    \"neut\": 0,\n",
    "    \"max\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a9a64-fdf0-4af0-aefb-0f2d9cb1ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate opposite statements\n",
    "def build_prompt_do_statements_agree(video_info, statement_1, statement_2):\n",
    "    title = get_title(video_info)\n",
    "    lines = [\"You are a professional YouTube video comment analyst. Given a video title and a statement (or a comment) about the video, decide if the statements two agree. Note that it may be possible for a statement or a comment to express the desire for change or to voice disagreement.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    lines.append(f\"Statement 1: {statement_1}\")\n",
    "    lines.append(f\"Statement 2: {statement_2}\")\n",
    "\n",
    "    lines.append(\"\\nA statement is a simple thought expressed by many comments, e.g., \\\"The video was well-edited.\\\" or \\\"I disagree with the premise of the video.\\\".\")\n",
    "    lines.append(f\"First, think step by step about the two statements to determine if they agree. Finally, give your assessment of the agreement on a scale of {agreement_prompt_settings['min']} for total disagreement to {agreement_prompt_settings['max']} for total agreement. \" \\\n",
    "                f\"The number {agreement_prompt_settings['neut']} is for unrelated statements (those which discuss different matters). Even if the sentiments of the statements are opposite: If they discuss different matters, the assessment should be {agreement_prompt_settings['neut']}. \" \\\n",
    "                 \"Provide your assessment in the form of JSON such as {\\\"agreement\\\": your_number_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e02847-0266-43c6-8ddf-cc25238ea4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_single_entry_json(raw):\n",
    "    # Split into lines\n",
    "    lines = raw.split(\"\\n\")\n",
    "\n",
    "    # Beginning from the bottom, try to read JSON using a regex\n",
    "    pattern = r'\\{.*?\\}'\n",
    "    jso = None\n",
    "    for line in reversed(lines):\n",
    "        # Match regex\n",
    "        matches = re.findall(pattern, line)\n",
    "        \n",
    "        if len(matches) == 0:\n",
    "            continue\n",
    "\n",
    "        # Parse json\n",
    "        for m in reversed(matches):\n",
    "            try:\n",
    "                jso = json.loads(m)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if jso is not None:\n",
    "            break\n",
    "\n",
    "    # Abort if we did not find JSON\n",
    "    if jso is None:\n",
    "        return None\n",
    "\n",
    "    # Extract only key in json\n",
    "    if len(jso) > 1:\n",
    "        return None  # invalid json\n",
    "    val = list(jso.values())[0]\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637a5e8-c892-467e-b6c9-aeaaf0760e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving agreements to disk\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd267cc-521f-4a9a-a069-8de97cb41492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for line count\n",
    "def get_line_count(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        num_lines = sum(1 for _ in f)\n",
    "    return num_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30434ded-d161-4123-9ba9-7a1b1228d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet saving function - will automatically chunk saved information into files\n",
    "def save_snippet(sni, name, max_entries_per_file=1000):\n",
    "    # Make a DataFrame with the new piece of information\n",
    "    df = pd.DataFrame([sni])\n",
    "\n",
    "    # Make destination directory\n",
    "    directory = os.path.join(data_dir, name)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Inspect already present files\n",
    "    found_files = sorted(glob(os.path.join(directory, \"*.csv\")))\n",
    "    if len(found_files) > 0:\n",
    "        # Find out ID of last file\n",
    "        last_path = found_files[-1]\n",
    "        last_filename = os.path.split(last_path)[-1]\n",
    "        last_filename = os.path.splitext(last_filename)[0]\n",
    "        file_id = int(last_filename.split(\"_\")[-1])\n",
    "\n",
    "        # Find out its number of entries\n",
    "        num_entries = get_line_count(last_path) - 1\n",
    "        if num_entries >= max_entries_per_file:\n",
    "            # Create a new file\n",
    "            file_id += 1\n",
    "        else:\n",
    "            # Load the file and append to it\n",
    "            df_old = pd.read_csv(last_path)\n",
    "            df = pd.concat([df_old, df])\n",
    "    else:\n",
    "        file_id = 0\n",
    "\n",
    "    # Save file\n",
    "    filename = f\"{name}_{file_id:06d}.csv\"\n",
    "    df.to_csv(os.path.join(directory, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68a250-d08c-4fb9-866c-7ab6825e86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full process of agreement check\n",
    "def do_statements_agree(video_info, statement_1, statement_2, verbose=False):\n",
    "    # Make prompt\n",
    "    prompt = build_prompt_do_statements_agree(video_info, statement_1, statement_2)\n",
    "\n",
    "    # Send prompt to LLM\n",
    "    res_raw = llm.chat(prompt)\n",
    "    if verbose:\n",
    "        print(f\"Raw LLM response: {res_raw}\")\n",
    "    rating = post_process_single_entry_json(res_raw)\n",
    "\n",
    "    # Save this snippet of information to a file\n",
    "    save_snippet(\n",
    "        {\n",
    "            \"statement_1\": statement_1,\n",
    "            \"statement_2\": statement_2,\n",
    "            \"video_title\": get_title(video_info),\n",
    "            \"agreement_rating\": rating\n",
    "        },\n",
    "        \"agreements\"\n",
    "    )\n",
    "\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac23e9-6b68-4fd7-9e2a-ad66329d7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top k comments, according to likes\n",
    "k = 2\n",
    "comments_topk = sorted(comments, key=lambda comm: comm.likes, reverse=True)[:k]\n",
    "comments_topk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b791e9c-ed3d-4f84-8734-c9993a0432b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_positive = \"agree\"\n",
    "agreement_neutral = \"neutral\"\n",
    "agreement_negative = \"disagree\"\n",
    "agreements_nonneutral = [agreement_positive, agreement_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74724498-d4a0-4628-aa03-27a63f5c014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_scores_raw = defaultdict(list)\n",
    "statement_agreements_raw = defaultdict(dict)\n",
    "\n",
    "statements = sum(comment_statements.values(), [])  # get all statements, regardless of kind\n",
    "comparisons_all = list(itertools.product(statements, comments_topk))\n",
    "for statement, comment in tqdm(comparisons_all, desc=\"Measuring statement agreement with comments ...\"):\n",
    "    # Find out agreement between statement and comment\n",
    "    agreement = do_statements_agree(\n",
    "        video_info=info,\n",
    "        statement_1=statement,\n",
    "        statement_2=comment.text\n",
    "    )\n",
    "\n",
    "    # Calculate agreement score\n",
    "    likes = comment.likes\n",
    "    score = agreement * likes\n",
    "\n",
    "    # Add measured score to the statement's score\n",
    "    statement_scores_raw[statement].append(score)\n",
    "\n",
    "    # Add likes to agreement class\n",
    "    agreement_class = agreement_positive if agreement > 0 else (agreement_negative if agreement < 0 else agreement_neutral)\n",
    "    tally = statement_agreements_raw[statement]\n",
    "    if agreement_class not in tally:\n",
    "        tally[agreement_class] = []\n",
    "    tally[agreement_class].append(likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0b628-8d76-4ee2-a14a-a0020ea003c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total like count to \"normalize\" scores\n",
    "total_likes = np.sum([comm.likes for comm in comments_topk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118b896-331a-4f92-9126-79417133ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize scores by using total like count\n",
    "statement_scores_norm = {statement: [s / total_likes for s in scores] for (statement, scores) in statement_scores_raw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4f249-5437-422a-9cd4-dda419e1ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum agreements to get scores\n",
    "statement_scores_total = {statement: np.sum(scores) for (statement, scores) in statement_scores_norm.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50445c3f-9a10-4c4e-9079-bb65a8c13b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for statement, score in statement_scores_total.items():\n",
    "    print(f\"Statement '{statement}'\".ljust(15 + max(len(s) for s in statements)) + f\"->\" + f\"{score:0.2f}\".rjust(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bc2a8-85c9-4400-a730-cf1f2c689e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the fraction of comments (weighted by likes) that agree, are neutral, or disagree\n",
    "statement_agreements_norm = {statement: {opinion: sum(likes) / total_likes for (opinion, likes) in agree_info.items()} for (statement, agree_info) in statement_agreements_raw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e37456-5748-41cd-a726-729b02319148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for statement, agree_info in statement_agreements_norm.items():\n",
    "    # Remove neutral votes (but remember them)\n",
    "    frac_neutral = agree_info.get(agreement_neutral, 0)\n",
    "    frac_engaged = 1 - frac_neutral\n",
    "\n",
    "    # Re-normalize other votes\n",
    "    if frac_neutral > 0:\n",
    "        prob_mass = sum(agree_info.get(opinion, 0) for opinion in agreements_nonneutral)\n",
    "        agree_info = {opinion: frac / prob_mass for (opinion, frac) in agree_info.items()}\n",
    "\n",
    "    # Sort opinions alphabetically and keep only non-neutral opinions\n",
    "    agree_info = sorted(agree_info.items(), key=lambda t: t[0])\n",
    "    agree_info = [(opinion, fraction) for (opinion, fraction) in agree_info if opinion in agreements_nonneutral]\n",
    "\n",
    "    # Format everything\n",
    "    statement_str = f\"Statement '{statement}'\".ljust(15 + max(len(s) for s in statements))\n",
    "    if frac_engaged > 0:\n",
    "        engagement_str = f\"{100 * frac_engaged:0.2f}% are discussing this, out of those \"\n",
    "        opinion_str = \", \".join(f\"{100 * fraction:0.0f}% {opinion}\" for (opinion, fraction) in agree_info).center(24)\n",
    "        discussion_str = engagement_str + opinion_str\n",
    "    else:\n",
    "        discussion_str = \"No comments (of those checked) are discussing this.\"\n",
    "    \n",
    "    print(statement_str + f\"->  \" + discussion_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5c927-bf5e-4e03-a6d0-836f8911445d",
   "metadata": {},
   "source": [
    "### Run classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30437e27-5ee2-41be-bfda-8fc16f6f7ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"All results are weighted by comment likes.\")\n",
    "for classi_type in ClassificationType:\n",
    "    classification_analysis(comments, classi_type)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52180ef6-3130-4cf7-a50e-c90492468cb1",
   "metadata": {},
   "source": [
    "## Embedding and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafec46a-adaf-4edd-9ac8-e5b4b8622d22",
   "metadata": {},
   "source": [
    "Here, our goal is to find out trends or common themes in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab31c-4d4b-4d1f-87f6-454d5e024638",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_for_clustering = flatten_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e942ad-f8e5-4cfe-af8a-89c7102997b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vecs = []\n",
    "for comm in tqdm(comments_for_clustering, desc=\"Calculating embeddings ...\"):\n",
    "    emb_vecs.append(comm.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f790aa5-53f9-4b50-be56-0de9d7b47d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.stack(emb_vecs)\n",
    "emb_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ded057-e3fb-471c-9878-cdb73980b04b",
   "metadata": {},
   "source": [
    "Let's cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911c81a-045c-4ae7-b2d9-700fce0d785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(matrix, n=5):\n",
    "    clustering_method = KMeans(n_clusters=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc172c-5b51-4094-91c3-1f2b815a67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_spectral_clustering(matrix, n=5):\n",
    "    clustering_method = SpectralClustering(n_clusters=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401638a0-2533-462b-b211-7e7802dc95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_dbscan(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = DBSCAN()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75efb2-7c26-4e4e-9fd8-298cc80a0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_optics(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = OPTICS()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f023f51-c432-4fd8-925a-5249d8fb0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hdbscan(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = HDBSCAN()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678f98a-5ec4-4508-8a22-b9d80b39b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(matrix, n=5):\n",
    "    clustering_method = GaussianMixture(n_components=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    labels = clustering_method.predict(matrix)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c965090-39c5-48b4-af63-fb3b9cc04060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_clustering(matrix, labels):\n",
    "    labs_unique = list(np.unique(labels))\n",
    "    \n",
    "    # Silhouette score for each sample (i.e., comment)\n",
    "    try:\n",
    "        sil_all = silhouette_samples(matrix, labels)\n",
    "    except ValueError:\n",
    "        # this may happen if there is only one label\n",
    "        sil_all = np.copy(labels)\n",
    "        sil_all.fill(-1)  # worst possible value\n",
    "    \n",
    "    # Silhouette score, aggregated by cluster\n",
    "    sil_for_labels = [np.mean(sil_all[np.where(labels == lab)[0]]) for lab in labs_unique]\n",
    "    \n",
    "    return labs_unique, sil_for_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb495a67-8fd8-4243-8067-f8957bb7a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterings = []\n",
    "n_range = [2, 3, 4, 5, 6, 7, 8, 16, 32, 64]\n",
    "clus_funs = [cluster_kmeans, cluster_gmm, cluster_spectral_clustering, cluster_hdbscan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29c632-cb05-4ab9-ad9a-6eac2dd7fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, clus_fun in tqdm(list(itertools.product(n_range, clus_funs)), desc=\"Clustering ...\"):\n",
    "    # Cluster\n",
    "    labels = clus_fun(emb_matrix, n=n)\n",
    "\n",
    "    # Evaluate\n",
    "    labs_unique, sil_for_labels = eval_clustering(emb_matrix, labels)\n",
    "    \n",
    "    clusterings.append((labels, labs_unique, sil_for_labels, n, clus_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d59ba1-ec03-46af-88bc-31af13440362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove clustering if it is degenerate (i.e., the majority of points are in a single cluster)\n",
    "cluster_sizes = [[len(np.where(labels == lab)[0]) / len(labels) for lab in labs_unique] for (labels, labs_unique, _, _, _) in clusterings]\n",
    "cluster_sizes = [(idx, si, min(2 / len(si), 0.8)) for (idx, si) in enumerate(cluster_sizes)]\n",
    "legal_indices = [idx for (idx, si, limit) in cluster_sizes if (max(si) <= limit)]\n",
    "clusterings = [clusterings[idx] for idx in legal_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f7405-5336-4c58-8b07-ce5a37590c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"After filtering out degenerate clusterings, proceeding with {len(clusterings)} clusterings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36d705-15d0-482c-9192-e32c765e4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by mean of Silhouette coefficient: largest first\n",
    "clusterings.sort(key=lambda t: np.mean(t[2]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bbe85-020d-47c7-92d8-91837321d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best clustering\n",
    "labels, labs_unique, sil_for_labels, n, clus_fun = clusterings[0]\n",
    "print(f\"Best clustering out of {len(clusterings)} is with n = {n}, with a mean Silhouette coefficient of {np.mean(sil_for_labels):0.8f} (function was {clus_fun}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede85cc1-a251-4c31-9275-c80df6c38c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare colormap for plotting\n",
    "cm_steps = len(labs_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e35e93-a602-4800-879a-8fefd23627cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = mpl.colormaps.get_cmap('hsv')\n",
    "cmap = mpl.colors.ListedColormap(hsv(np.linspace(0,1,cm_steps + 1)[:-1]))\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d5e5d-665c-4a91-80d0-7f65489252aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_for_idx(idx, colormap):\n",
    "    return colormap.colors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ee829-c412-4839-b9b6-15371dbba51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_for_label(label, labels_unique, colormap):\n",
    "    idx = labels_unique.index(label)\n",
    "    return color_for_idx(idx, colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f117801-60a8-4de7-9bcc-4d37f9ae56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(matrix, labels_unique, labels, use_umap=True):\n",
    "    if use_umap:\n",
    "        # Use UMAP\n",
    "        reducer = umap.UMAP()\n",
    "    else:\n",
    "        # Use t-SNE\n",
    "        reducer = TSNE(\n",
    "            n_components=2,\n",
    "            learning_rate='auto',\n",
    "            init='random',\n",
    "            perplexity=3\n",
    "        )\n",
    "\n",
    "    # Fit\n",
    "    matrix_2d = reducer.fit_transform(matrix)\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(x=matrix_2d[:, 0], y=matrix_2d[:, 1], c=[color_for_label(lab, labels_unique, cmap) for lab in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67228b73-7cf2-443a-ac6f-2b7488392ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(emb_matrix, labs_unique, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dacae4-2712-43da-855a-45591b669712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_find_topic(video_info, comments: List[Comment]):\n",
    "    title = get_title(video_info)\n",
    "    lines = [f\"You are a professional YouTube comment analyst. Given a video title and some comments, find the topic of the comments.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    \n",
    "    lines.append(\"\\nSample from the comments:\")\n",
    "    comm_lines = sample_from_comments(comments)\n",
    "    lines += comm_lines\n",
    "\n",
    "    lines.append(\"\\nExtract a single, coherent topic that these comments are discussing. The topic you find can also be about the style or mood of the comments. \" \\\n",
    "                 \"A topic should be a simple notion, e.g., \\\"Jokes\\\" or \\\"Choosing a keyboard\\\".\" \\\n",
    "                 \"There is no need to repeat the video title in your assessment. The topic should also describe what the comments are saying, so it shouldn't be, e.g., \\\"Reactions to Video\\\" or anything generic of that sort. Provide your assessment in the form of JSON such as {\\\"topic\\\": your_topic_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9310abe-a5a5-4fff-85ff-fbac915643a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "divider_width = 100\n",
    "divider_str = \"-\"\n",
    "show_random_comments = False\n",
    "cluster_topics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da8e59-9513-403c-a651-d30480fd71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_clusters():\n",
    "    for lab in labs_unique:\n",
    "        print(f\"Cluster Description (Label {lab})\".center(divider_width, divider_str))\n",
    "    \n",
    "        # Size\n",
    "        cluster_size = sum(labels == lab)\n",
    "        print(f\"- Cluster size: {cluster_size} ({100 * cluster_size / len(labels):0.2f}%)\")\n",
    "    \n",
    "        # Get indices\n",
    "        clus_indices = np.where(labels == lab)[0]\n",
    "        \n",
    "        # Find mean embedding of cluster\n",
    "        clus_mean_emb = np.mean(np.stack([emb_matrix[idx] for idx in clus_indices]), axis=0)\n",
    "        \n",
    "        # Sort comments by distance to mean embedding\n",
    "        clus_comments = [comments_for_clustering[idx] for idx in clus_indices]\n",
    "        clus_comments.sort(key=lambda comment: np.sum(np.abs(comment.get_embedding()) - clus_mean_emb))\n",
    "    \n",
    "        # Find out central topic of cluster\n",
    "        if lab not in cluster_topics:\n",
    "            clus_comments_central = clus_comments[:1000]\n",
    "            prompt = build_prompt_find_topic(info, clus_comments_central)\n",
    "            res_raw = llm.chat(prompt)\n",
    "            topic = post_process_single_entry_json(res_raw)\n",
    "            cluster_topics[lab] = topic\n",
    "        print(f\"- Central topic (LLM): {cluster_topics[lab]}\")\n",
    "    \n",
    "        # Show comment closest to the mean\n",
    "        print(\"- Comment closest to mean embedding:\")\n",
    "        print(clus_comments[0])\n",
    "    \n",
    "        # Show random comments\n",
    "        if show_random_comments:\n",
    "            rnd_indices = np.random.choice(clus_indices, size=min(5, cluster_size), replace=False)\n",
    "            print()\n",
    "            print(f\"- {len(rnd_indices)} random comments from this cluster: \")\n",
    "            for idx in rnd_indices:\n",
    "                print(f\"- {comments_for_clustering[idx]}\")\n",
    "    \n",
    "        print(\"\".center(divider_width, divider_str))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca511d-5bf3-477e-b0f4-cc7f8d0d0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31618677-8090-4f2d-8eb9-5759562a374c",
   "metadata": {},
   "source": [
    "### Fuse clusters based on topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047eb02-ad8e-4014-877c-5974b0c244cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_groups = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb239f-e256-4248-90b0-1b25b4248aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab, topic in cluster_topics.items():\n",
    "    # Store this cluster label and topic as a tuple\n",
    "    tup = (lab, topic)\n",
    "    \n",
    "    # Try to find a spot for this topic in one of the groups\n",
    "    found_group = False\n",
    "    for group in cluster_groups:\n",
    "\n",
    "        # If the group is empty, add the cluster (this only happens at the beginning)\n",
    "        if len(group) == 0:\n",
    "            group.append(tup)\n",
    "            found_group = True\n",
    "            break\n",
    "\n",
    "        # Compare this cluster's embedding with the group\n",
    "        mean_sim = np.mean([cos_sim(text_model_manager.embed(top), text_model_manager.embed(topic)) for (l, top) in group])\n",
    "        if mean_sim > 0.55:\n",
    "            group.append(tup)\n",
    "            found_group = True\n",
    "            break\n",
    "\n",
    "    # If we already found a group, go on to the next cluster's topic\n",
    "    if found_group:\n",
    "        continue\n",
    "\n",
    "    # Start a new group\n",
    "    cluster_groups.append([tup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb0ad4-8188-4215-8f5b-100bbee4023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_fuse_topics(video_info, topics: List[str]):\n",
    "    title = get_title(video_info)\n",
    "    lines = [f\"You are a professional YouTube comment analyst. Given a video title and some comment topics, find a new description of the topic that reflects the core concept of the listed topics.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    \n",
    "    lines.append(\"\\nComment topics:\")\n",
    "    lines += [f\"- {t}\" for t in topics]\n",
    "\n",
    "    lines.append(\"\\nExtract a single, coherent topic that describes all these topics. The topic you find can also be about the style or mood of the comments. \" \\\n",
    "                 \"A topic should be a simple notion, e.g., \\\"Jokes\\\" or \\\"Choosing a keyboard\\\".\" \\\n",
    "                 \"There is no need to repeat the video title in your assessment. The topic shouldn't be, e.g., \\\"Reactions to Video\\\" or anything generic of that sort. Provide your assessment in the form of JSON such as {\\\"topic\\\": your_topic_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7971b2-6e07-4392-a128-440611be1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse groups we found by finding a new topic\n",
    "fused_groups = []\n",
    "for group in tqdm(cluster_groups, desc=\"Fusing groups ...\"):\n",
    "    labs, topics = zip(*group)\n",
    "\n",
    "    if len(topics) > 1:\n",
    "        prompt = build_prompt_fuse_topics(info, topics)\n",
    "        res_raw = llm.chat(prompt)\n",
    "        topic = post_process_single_entry_json(res_raw)\n",
    "    else:\n",
    "        topic = topics[0]\n",
    "\n",
    "    fused_groups.append((labs, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225976d-8fc4-4e7b-a50b-d4cabe2aee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labeling of clustering to reflect group fusions\n",
    "for label_group, topic in fused_groups:\n",
    "    # No need to change any labels if we \"group\" doesn't have multiple labels\n",
    "    if len(label_group) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Paint all labels in group to match the first label\n",
    "    label_group = list(label_group)\n",
    "    lab_first = label_group.pop(0)\n",
    "    for lab in label_group:\n",
    "        labels[np.where(labels == lab)] = lab_first\n",
    "\n",
    "    # Remember topic\n",
    "    cluster_topics[lab_first] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39160f07-4b5f-4ea0-9c77-302d7fd3e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_unique = list(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411dcbe-0337-48ae-bb01-047ba031f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(emb_matrix, labs_unique, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf6ac1-d320-4a48-9ba2-0a8e53c145ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_clusters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_comments",
   "language": "python",
   "name": "yt_comments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
