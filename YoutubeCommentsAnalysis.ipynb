{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd68cc20-4983-44a7-b931-27cf92fc6113",
   "metadata": {},
   "source": [
    "# Youtube Comments Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bea4d9-e984-4607-a401-f9a89ee8855a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3d9793-14fe-41b6-88b4-3b63c54cec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json\n",
    "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN, HDBSCAN, OPTICS\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cfeb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# My own modules\n",
    "from util.string_utils import split_text_if_long\n",
    "from models.text_models import TextModelManager\n",
    "from models.computations import ClassificationType\n",
    "from models.math_funcs import cos_sim\n",
    "from models.llm_api import LLM\n",
    "from api.youtube_api import YoutubeAPI\n",
    "from analysis.classification_analysis import ClassificationAnalyzer\n",
    "from analysis.statements_analysis import StatementsAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b909081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s.%(msecs)03d - %(name)s - %(levelname)s - %(message)s',  # Define the log format with milliseconds\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Define the date and time format without milliseconds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e5103-a2f5-4dbb-8f20-65cfaf3cc7eb",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec47aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 23:53:21.988 - models.text_models - INFO - Instantiating TextModelManager.\n"
     ]
    }
   ],
   "source": [
    "# Initialize classification models\n",
    "text_model_manager = TextModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dca2b-1349-4677-a502-4ee1d719fadf",
   "metadata": {},
   "source": [
    "## Set up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ca201e-fb9d-43dd-9507-bdfafc6e439a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 23:53:21.999 - models.llm_api - INFO - Instantiating LLM.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf2fc6-a49a-4ace-9bca-249703491ef4",
   "metadata": {},
   "source": [
    "## Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a4f8cc-e459-4cf6-b584-2c574310d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 23:53:22.038 - api.youtube_api - INFO - Instantiating YoutubeAPI.\n",
      "2024-07-27 23:53:22.042 - googleapiclient.discovery_cache - INFO - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "youtube = YoutubeAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f56fdad-bc02-4a3a-9dbb-2ab2514d677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_video_test_id_tomato = \"9WQnap-UAiQ\"\n",
    "yt_video_test_id_10k_comments = \"2-XxbdR3Nik\"\n",
    "yt_video_test_id_4500_comments = \"-ih0B9yn32Q\"\n",
    "yt_video_test_id_4k_comments_beard_meets_schnitzel = \"qPd9qPUR2_U\"\n",
    "yt_video_test_id_2000_comments = \"rX2tK-qSVpk\"\n",
    "yt_video_test_id_700_comments = \"VCXqELB3UPg\"\n",
    "yt_video_test_id_300_comments = \"yQqJafC7xv0\"\n",
    "yt_video_test_id_25_comments = \"kiF0wgM8zGc\"\n",
    "yt_video_test_id_50_comments = \"LHQMIuzjl48\"\n",
    "\n",
    "yt_video_id = yt_video_test_id_50_comments\n",
    "youtube.set_current_video(yt_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bccbd94-3da0-4d75-8460-79772a19c6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perfect OFFICE Custom Keyboard!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube.get_title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e329998-2c17-45a9-bae5-87a9128d79d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lewis Toh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube.get_creator_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b068b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 23:53:22.271 - api.youtube_api - INFO - Starting raw comment retrieval.\n",
      "2024-07-27 23:53:22.411 - api.youtube_api - INFO - Received 31 top-level comments.\n",
      "2024-07-27 23:53:22.412 - api.youtube_api - INFO - Finished raw comment retrieval of 31 top-level comments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comments retrieval for video ID LHQMIuzjl48 ('Perfect OFFICE Custom Keyboard!')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting replies for comments with missing replies ...: 100%|██████████| 31/31 [00:00<00:00, 137155.51it/s]\n",
      "Converting comments to our own class ...: 100%|██████████| 31/31 [00:00<00:00, 4851.26it/s]\n",
      "Deduplicating comments ...: 100%|██████████| 31/31 [00:00<00:00, 9276.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get comments (for testing)\n",
    "comments = youtube.get_comments(yt_video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4af2d",
   "metadata": {},
   "source": [
    "## LLM Statement Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ceb7698-7fa3-44c7-ad95-8757a4981742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 23:53:22.445 - googleapiclient.discovery_cache - INFO - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "statements_analyzer = StatementsAnalyzer(\n",
    "    video_id=yt_video_id,\n",
    "    comments=comments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07710002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grouping by sentiment ...: 100%|██████████| 31/31 [00:01<00:00, 20.36it/s]\n",
      "Measuring statement agreement with comments ...: 100%|██████████| 124/124 [03:40<00:00,  1.78s/it]\n",
      "2024-07-27 23:57:08.472 - analysis.statements_analysis - INFO - Score for statement 'The video makes me want to try out other keyboards.' -> 0.31\n",
      "2024-07-27 23:57:08.472 - analysis.statements_analysis - INFO - Score for statement 'The keyboard is a good value for its price.' -> 0.63\n",
      "2024-07-27 23:57:08.473 - analysis.statements_analysis - INFO - Score for statement 'The black version of the keyboard looks great.' -> 1.04\n",
      "2024-07-27 23:57:08.473 - analysis.statements_analysis - INFO - Score for statement 'Some viewers are experiencing issues with their keyboard, such as ticking noises or double spacing.' -> -0.25\n",
      "2024-07-27 23:57:08.474 - analysis.statements_analysis - INFO - Statement 'The video makes me want to try out other keyboards.'->  8.82% are discussing this, out of those 100% agree\n",
      "2024-07-27 23:57:08.474 - analysis.statements_analysis - INFO - Statement 'The keyboard is a good value for its price.'->  25.00% are discussing this, out of those 82% agree, 18% disagree\n",
      "2024-07-27 23:57:08.475 - analysis.statements_analysis - INFO - Statement 'The black version of the keyboard looks great.'->  25.00% are discussing this, out of those 100% agree\n",
      "2024-07-27 23:57:08.476 - analysis.statements_analysis - INFO - Statement 'Some viewers are experiencing issues with their keyboard, such as ticking noises or double spacing.'->  17.65% are discussing this, out of those 25% agree, 75% disagree\n"
     ]
    }
   ],
   "source": [
    "statements_analyzer.run_analysis(\n",
    "    limit_statements=2  # For testing, limit number of statements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52180ef6-3130-4cf7-a50e-c90492468cb1",
   "metadata": {},
   "source": [
    "## Embedding and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafec46a-adaf-4edd-9ac8-e5b4b8622d22",
   "metadata": {},
   "source": [
    "Here, our goal is to find out trends or common themes in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0beec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfda62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffcaedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab31c-4d4b-4d1f-87f6-454d5e024638",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_for_clustering = flatten_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e942ad-f8e5-4cfe-af8a-89c7102997b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vecs = []\n",
    "for comm in tqdm(comments_for_clustering, desc=\"Calculating embeddings ...\"):\n",
    "    emb_vecs.append(comm.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f790aa5-53f9-4b50-be56-0de9d7b47d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.stack(emb_vecs)\n",
    "emb_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ded057-e3fb-471c-9878-cdb73980b04b",
   "metadata": {},
   "source": [
    "Let's cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911c81a-045c-4ae7-b2d9-700fce0d785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(matrix, n=5):\n",
    "    clustering_method = KMeans(n_clusters=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc172c-5b51-4094-91c3-1f2b815a67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_spectral_clustering(matrix, n=5):\n",
    "    clustering_method = SpectralClustering(n_clusters=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401638a0-2533-462b-b211-7e7802dc95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_dbscan(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = DBSCAN()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75efb2-7c26-4e4e-9fd8-298cc80a0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_optics(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = OPTICS()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f023f51-c432-4fd8-925a-5249d8fb0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hdbscan(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = HDBSCAN()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678f98a-5ec4-4508-8a22-b9d80b39b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(matrix, n=5):\n",
    "    clustering_method = GaussianMixture(n_components=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    labels = clustering_method.predict(matrix)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c965090-39c5-48b4-af63-fb3b9cc04060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_clustering(matrix, labels):\n",
    "    labs_unique = list(np.unique(labels))\n",
    "    \n",
    "    # Silhouette score for each sample (i.e., comment)\n",
    "    try:\n",
    "        sil_all = silhouette_samples(matrix, labels)\n",
    "    except ValueError:\n",
    "        # this may happen if there is only one label\n",
    "        sil_all = np.copy(labels)\n",
    "        sil_all.fill(-1)  # worst possible value\n",
    "    \n",
    "    # Silhouette score, aggregated by cluster\n",
    "    sil_for_labels = [np.mean(sil_all[np.where(labels == lab)[0]]) for lab in labs_unique]\n",
    "    \n",
    "    return labs_unique, sil_for_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb495a67-8fd8-4243-8067-f8957bb7a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterings = []\n",
    "n_range = [2, 3, 4, 5, 6, 7, 8, 16, 32, 64]\n",
    "clus_funs = [cluster_kmeans, cluster_gmm, cluster_spectral_clustering, cluster_hdbscan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29c632-cb05-4ab9-ad9a-6eac2dd7fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, clus_fun in tqdm(list(itertools.product(n_range, clus_funs)), desc=\"Clustering ...\"):\n",
    "    # Cluster\n",
    "    labels = clus_fun(emb_matrix, n=n)\n",
    "\n",
    "    # Evaluate\n",
    "    labs_unique, sil_for_labels = eval_clustering(emb_matrix, labels)\n",
    "    \n",
    "    clusterings.append((labels, labs_unique, sil_for_labels, n, clus_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d59ba1-ec03-46af-88bc-31af13440362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove clustering if it is degenerate (i.e., the majority of points are in a single cluster)\n",
    "cluster_sizes = [[len(np.where(labels == lab)[0]) / len(labels) for lab in labs_unique] for (labels, labs_unique, _, _, _) in clusterings]\n",
    "cluster_sizes = [(idx, si, min(2 / len(si), 0.8)) for (idx, si) in enumerate(cluster_sizes)]\n",
    "legal_indices = [idx for (idx, si, limit) in cluster_sizes if (max(si) <= limit)]\n",
    "clusterings = [clusterings[idx] for idx in legal_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f7405-5336-4c58-8b07-ce5a37590c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"After filtering out degenerate clusterings, proceeding with {len(clusterings)} clusterings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36d705-15d0-482c-9192-e32c765e4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by mean of Silhouette coefficient: largest first\n",
    "clusterings.sort(key=lambda t: np.mean(t[2]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bbe85-020d-47c7-92d8-91837321d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best clustering\n",
    "labels, labs_unique, sil_for_labels, n, clus_fun = clusterings[0]\n",
    "print(f\"Best clustering out of {len(clusterings)} is with n = {n}, with a mean Silhouette coefficient of {np.mean(sil_for_labels):0.8f} (function was {clus_fun}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede85cc1-a251-4c31-9275-c80df6c38c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare colormap for plotting\n",
    "cm_steps = len(labs_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e35e93-a602-4800-879a-8fefd23627cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = mpl.colormaps.get_cmap('hsv')\n",
    "cmap = mpl.colors.ListedColormap(hsv(np.linspace(0,1,cm_steps + 1)[:-1]))\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d5e5d-665c-4a91-80d0-7f65489252aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_for_idx(idx, colormap):\n",
    "    return colormap.colors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ee829-c412-4839-b9b6-15371dbba51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_for_label(label, labels_unique, colormap):\n",
    "    idx = labels_unique.index(label)\n",
    "    return color_for_idx(idx, colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f117801-60a8-4de7-9bcc-4d37f9ae56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(matrix, labels_unique, labels, use_umap=True):\n",
    "    if use_umap:\n",
    "        # Use UMAP\n",
    "        reducer = umap.UMAP()\n",
    "    else:\n",
    "        # Use t-SNE\n",
    "        reducer = TSNE(\n",
    "            n_components=2,\n",
    "            learning_rate='auto',\n",
    "            init='random',\n",
    "            perplexity=3\n",
    "        )\n",
    "\n",
    "    # Fit\n",
    "    matrix_2d = reducer.fit_transform(matrix)\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(x=matrix_2d[:, 0], y=matrix_2d[:, 1], c=[color_for_label(lab, labels_unique, cmap) for lab in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67228b73-7cf2-443a-ac6f-2b7488392ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(emb_matrix, labs_unique, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dacae4-2712-43da-855a-45591b669712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_find_topic(video_info, comments: List[Comment]):\n",
    "    title = get_title(video_info)\n",
    "    lines = [f\"You are a professional YouTube comment analyst. Given a video title and some comments, find the topic of the comments.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    \n",
    "    lines.append(\"\\nSample from the comments:\")\n",
    "    comm_lines = sample_from_comments(comments)\n",
    "    lines += comm_lines\n",
    "\n",
    "    lines.append(\"\\nExtract a single, coherent topic that these comments are discussing. The topic you find can also be about the style or mood of the comments. \" \\\n",
    "                 \"A topic should be a simple notion, e.g., \\\"Jokes\\\" or \\\"Choosing a keyboard\\\".\" \\\n",
    "                 \"There is no need to repeat the video title in your assessment. The topic should also describe what the comments are saying, so it shouldn't be, e.g., \\\"Reactions to Video\\\" or anything generic of that sort. Provide your assessment in the form of JSON such as {\\\"topic\\\": your_topic_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9310abe-a5a5-4fff-85ff-fbac915643a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "divider_width = 100\n",
    "divider_str = \"-\"\n",
    "show_random_comments = False\n",
    "cluster_topics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da8e59-9513-403c-a651-d30480fd71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_clusters():\n",
    "    for lab in labs_unique:\n",
    "        print(f\"Cluster Description (Label {lab})\".center(divider_width, divider_str))\n",
    "    \n",
    "        # Size\n",
    "        cluster_size = sum(labels == lab)\n",
    "        print(f\"- Cluster size: {cluster_size} ({100 * cluster_size / len(labels):0.2f}%)\")\n",
    "    \n",
    "        # Get indices\n",
    "        clus_indices = np.where(labels == lab)[0]\n",
    "        \n",
    "        # Find mean embedding of cluster\n",
    "        clus_mean_emb = np.mean(np.stack([emb_matrix[idx] for idx in clus_indices]), axis=0)\n",
    "        \n",
    "        # Sort comments by distance to mean embedding\n",
    "        clus_comments = [comments_for_clustering[idx] for idx in clus_indices]\n",
    "        clus_comments.sort(key=lambda comment: np.sum(np.abs(comment.get_embedding()) - clus_mean_emb))\n",
    "    \n",
    "        # Find out central topic of cluster\n",
    "        if lab not in cluster_topics:\n",
    "            clus_comments_central = clus_comments[:1000]\n",
    "            prompt = build_prompt_find_topic(info, clus_comments_central)\n",
    "            res_raw = llm.chat(prompt)\n",
    "            topic = post_process_single_entry_json(res_raw)\n",
    "            cluster_topics[lab] = topic\n",
    "        print(f\"- Central topic (LLM): {cluster_topics[lab]}\")\n",
    "    \n",
    "        # Show comment closest to the mean\n",
    "        print(\"- Comment closest to mean embedding:\")\n",
    "        print(clus_comments[0])\n",
    "    \n",
    "        # Show random comments\n",
    "        if show_random_comments:\n",
    "            rnd_indices = np.random.choice(clus_indices, size=min(5, cluster_size), replace=False)\n",
    "            print()\n",
    "            print(f\"- {len(rnd_indices)} random comments from this cluster: \")\n",
    "            for idx in rnd_indices:\n",
    "                print(f\"- {comments_for_clustering[idx]}\")\n",
    "    \n",
    "        print(\"\".center(divider_width, divider_str))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca511d-5bf3-477e-b0f4-cc7f8d0d0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31618677-8090-4f2d-8eb9-5759562a374c",
   "metadata": {},
   "source": [
    "### Fuse clusters based on topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047eb02-ad8e-4014-877c-5974b0c244cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_groups = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb239f-e256-4248-90b0-1b25b4248aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab, topic in cluster_topics.items():\n",
    "    # Store this cluster label and topic as a tuple\n",
    "    tup = (lab, topic)\n",
    "    \n",
    "    # Try to find a spot for this topic in one of the groups\n",
    "    found_group = False\n",
    "    for group in cluster_groups:\n",
    "\n",
    "        # If the group is empty, add the cluster (this only happens at the beginning)\n",
    "        if len(group) == 0:\n",
    "            group.append(tup)\n",
    "            found_group = True\n",
    "            break\n",
    "\n",
    "        # Compare this cluster's embedding with the group\n",
    "        mean_sim = np.mean([cos_sim(text_model_manager.embed(top), text_model_manager.embed(topic)) for (l, top) in group])\n",
    "        if mean_sim > 0.55:\n",
    "            group.append(tup)\n",
    "            found_group = True\n",
    "            break\n",
    "\n",
    "    # If we already found a group, go on to the next cluster's topic\n",
    "    if found_group:\n",
    "        continue\n",
    "\n",
    "    # Start a new group\n",
    "    cluster_groups.append([tup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb0ad4-8188-4215-8f5b-100bbee4023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_fuse_topics(video_info, topics: List[str]):\n",
    "    title = get_title(video_info)\n",
    "    lines = [f\"You are a professional YouTube comment analyst. Given a video title and some comment topics, find a new description of the topic that reflects the core concept of the listed topics.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    \n",
    "    lines.append(\"\\nComment topics:\")\n",
    "    lines += [f\"- {t}\" for t in topics]\n",
    "\n",
    "    lines.append(\"\\nExtract a single, coherent topic that describes all these topics. The topic you find can also be about the style or mood of the comments. \" \\\n",
    "                 \"A topic should be a simple notion, e.g., \\\"Jokes\\\" or \\\"Choosing a keyboard\\\".\" \\\n",
    "                 \"There is no need to repeat the video title in your assessment. The topic shouldn't be, e.g., \\\"Reactions to Video\\\" or anything generic of that sort. Provide your assessment in the form of JSON such as {\\\"topic\\\": your_topic_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7971b2-6e07-4392-a128-440611be1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse groups we found by finding a new topic\n",
    "fused_groups = []\n",
    "for group in tqdm(cluster_groups, desc=\"Fusing groups ...\"):\n",
    "    labs, topics = zip(*group)\n",
    "\n",
    "    if len(topics) > 1:\n",
    "        prompt = build_prompt_fuse_topics(info, topics)\n",
    "        res_raw = llm.chat(prompt)\n",
    "        topic = post_process_single_entry_json(res_raw)\n",
    "    else:\n",
    "        topic = topics[0]\n",
    "\n",
    "    fused_groups.append((labs, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225976d-8fc4-4e7b-a50b-d4cabe2aee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labeling of clustering to reflect group fusions\n",
    "for label_group, topic in fused_groups:\n",
    "    # No need to change any labels if we \"group\" doesn't have multiple labels\n",
    "    if len(label_group) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Paint all labels in group to match the first label\n",
    "    label_group = list(label_group)\n",
    "    lab_first = label_group.pop(0)\n",
    "    for lab in label_group:\n",
    "        labels[np.where(labels == lab)] = lab_first\n",
    "\n",
    "    # Remember topic\n",
    "    cluster_topics[lab_first] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39160f07-4b5f-4ea0-9c77-302d7fd3e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_unique = list(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411dcbe-0337-48ae-bb01-047ba031f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(emb_matrix, labs_unique, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf6ac1-d320-4a48-9ba2-0a8e53c145ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e000da",
   "metadata": {},
   "source": [
    "## Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_analyzer = ClassificationAnalyzer(comments)\n",
    "print(classification_analyzer.run_all_analyses())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_comments",
   "language": "python",
   "name": "yt_comments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
