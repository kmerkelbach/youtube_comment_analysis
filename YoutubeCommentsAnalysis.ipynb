{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd68cc20-4983-44a7-b931-27cf92fc6113",
   "metadata": {},
   "source": [
    "# Youtube Comments Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bea4d9-e984-4607-a401-f9a89ee8855a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3d9793-14fe-41b6-88b4-3b63c54cec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json\n",
    "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN, HDBSCAN, OPTICS\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6cfeb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# My own modules\n",
    "from util.string_utils import split_text_if_long\n",
    "from models.text_models import TextModelManager\n",
    "from models.computations import ClassificationType\n",
    "from models.math_funcs import cos_sim\n",
    "from models.llm_api import LLM\n",
    "from api.youtube_api import YoutubeAPI\n",
    "from analysis.classification_analysis import ClassificationAnalyzer\n",
    "from analysis.statements_analysis import StatementsAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b909081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s.%(msecs)03d - %(name)s - %(levelname)s - %(message)s',  # Define the log format with milliseconds\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Define the date and time format without milliseconds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e5103-a2f5-4dbb-8f20-65cfaf3cc7eb",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec47aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 01:04:43.241 - models.text_models - INFO - Instantiating TextModelManager.\n"
     ]
    }
   ],
   "source": [
    "# Initialize classification models\n",
    "text_model_manager = TextModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dca2b-1349-4677-a502-4ee1d719fadf",
   "metadata": {},
   "source": [
    "## Set up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ca201e-fb9d-43dd-9507-bdfafc6e439a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 01:04:43.251 - models.llm_api - INFO - Instantiating LLM.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf2fc6-a49a-4ace-9bca-249703491ef4",
   "metadata": {},
   "source": [
    "## Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a4f8cc-e459-4cf6-b584-2c574310d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 01:04:43.286 - api.youtube_api - INFO - Instantiating YoutubeAPI.\n",
      "2024-07-16 01:04:43.290 - googleapiclient.discovery_cache - INFO - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "youtube = YoutubeAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f56fdad-bc02-4a3a-9dbb-2ab2514d677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_video_test_id_tomato = \"9WQnap-UAiQ\"\n",
    "yt_video_test_id_10k_comments = \"2-XxbdR3Nik\"\n",
    "yt_video_test_id_4500_comments = \"-ih0B9yn32Q\"\n",
    "yt_video_test_id_4k_comments_beard_meets_schnitzel = \"qPd9qPUR2_U\"\n",
    "yt_video_test_id_2000_comments = \"rX2tK-qSVpk\"\n",
    "yt_video_test_id_700_comments = \"VCXqELB3UPg\"\n",
    "yt_video_test_id_300_comments = \"yQqJafC7xv0\"\n",
    "yt_video_test_id_25_comments = \"kiF0wgM8zGc\"\n",
    "yt_video_test_id_50_comments = \"LHQMIuzjl48\"\n",
    "\n",
    "yt_video_id = yt_video_test_id_50_comments\n",
    "youtube.set_current_video(yt_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bccbd94-3da0-4d75-8460-79772a19c6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perfect OFFICE Custom Keyboard!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube.get_title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e329998-2c17-45a9-bae5-87a9128d79d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lewis Toh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube.get_creator_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b068b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 01:04:43.492 - api.youtube_api - INFO - Starting raw comment retrieval.\n",
      "2024-07-16 01:04:43.627 - api.youtube_api - INFO - Received 31 top-level comments.\n",
      "2024-07-16 01:04:43.628 - api.youtube_api - INFO - Finished raw comment retrieval of 31 top-level comments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comments retrieval for video ID LHQMIuzjl48 ('Perfect OFFICE Custom Keyboard!')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting replies for comments with missing replies ...: 100%|██████████| 31/31 [00:00<00:00, 247192.82it/s]\n",
      "Converting comments to our own class ...: 100%|██████████| 31/31 [00:00<00:00, 3465.07it/s]\n",
      "Deduplicating comments ...: 100%|██████████| 31/31 [00:00<00:00, 14337.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get comments (for testing)\n",
    "comments = youtube.get_comments(yt_video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4af2d",
   "metadata": {},
   "source": [
    "## LLM Statement Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ceb7698-7fa3-44c7-ad95-8757a4981742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 01:04:43.659 - googleapiclient.discovery_cache - INFO - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "statements_analyzer = StatementsAnalyzer(\n",
    "    video_id=yt_video_id,\n",
    "    comments=comments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "160a69b4-4256-4fbc-a9ff-2f4a74f3a91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grouping by sentiment ...: 100%|██████████| 31/31 [00:01<00:00, 21.15it/s]\n",
      "2024-07-16 01:04:46.299 - httpx - INFO - HTTP Request: POST https://api.fireworks.ai/inference/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-07-16 01:04:47.095 - httpx - INFO - HTTP Request: POST https://api.fireworks.ai/inference/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "comment_statements = statements_analyzer.extract_statements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05f3e80b-9287-4d66-bda4-b208d6d65b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': ['I love the aesthetic of the keyboard.',\n",
       "  'The fish in the video needs a bigger tank.',\n",
       "  \"I'm interested in learning more about other keyboard options.\",\n",
       "  \"The video's soundtrack is great.\",\n",
       "  \"I appreciate the reviewer's honest feedback on keyboards.\"],\n",
       " 'negative': [\"I'm having trouble with my custom keyboard build.\",\n",
       "  'I expect higher quality components for the price.',\n",
       "  \"I'm not a fan of the sound of this keyboard.\",\n",
       "  'The design of this keyboard looks great.',\n",
       "  \"I'm interested in learning more about custom keyboard builds.\"]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca72a1c2-ccf2-4725-b717-c8a3c835f5e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing, reduce the number of statements\n",
    "comment_statements = {kind: [statements[idx] for idx in np.random.choice(np.arange(len(statements)), size=min(len(statements), 2), replace=False)] for (kind, statements) in comment_statements.items()}\n",
    "comment_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca3232-b303-47a7-8a6a-3d6517349de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_prompt_settings = {\n",
    "    \"min\": -5,\n",
    "    \"neut\": 0,\n",
    "    \"max\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a9a64-fdf0-4af0-aefb-0f2d9cb1ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate opposite statements\n",
    "def build_prompt_do_statements_agree(video_info, statement_1, statement_2):\n",
    "    title = get_title(video_info)\n",
    "    lines = [\"You are a professional YouTube video comment analyst. Given a video title and a statement (or a comment) about the video, decide if the statements two agree. Note that it may be possible for a statement or a comment to express the desire for change or to voice disagreement.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    lines.append(f\"Statement 1: {statement_1}\")\n",
    "    lines.append(f\"Statement 2: {statement_2}\")\n",
    "\n",
    "    lines.append(\"\\nA statement is a simple thought expressed by many comments, e.g., \\\"The video was well-edited.\\\" or \\\"I disagree with the premise of the video.\\\".\")\n",
    "    lines.append(f\"First, think step by step about the two statements to determine if they agree. Finally, give your assessment of the agreement on a scale of {agreement_prompt_settings['min']} for total disagreement to {agreement_prompt_settings['max']} for total agreement. \" \\\n",
    "                f\"The number {agreement_prompt_settings['neut']} is for unrelated statements (those which discuss different matters). Even if the sentiments of the statements are opposite: If they discuss different matters, the assessment should be {agreement_prompt_settings['neut']}. \" \\\n",
    "                 \"Provide your assessment in the form of JSON such as {\\\"agreement\\\": your_number_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e02847-0266-43c6-8ddf-cc25238ea4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_single_entry_json(raw):\n",
    "    # Split into lines\n",
    "    lines = raw.split(\"\\n\")\n",
    "\n",
    "    # Beginning from the bottom, try to read JSON using a regex\n",
    "    pattern = r'\\{.*?\\}'\n",
    "    jso = None\n",
    "    for line in reversed(lines):\n",
    "        # Match regex\n",
    "        matches = re.findall(pattern, line)\n",
    "        \n",
    "        if len(matches) == 0:\n",
    "            continue\n",
    "\n",
    "        # Parse json\n",
    "        for m in reversed(matches):\n",
    "            try:\n",
    "                jso = json.loads(m)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if jso is not None:\n",
    "            break\n",
    "\n",
    "    # Abort if we did not find JSON\n",
    "    if jso is None:\n",
    "        return None\n",
    "\n",
    "    # Extract only key in json\n",
    "    if len(jso) > 1:\n",
    "        return None  # invalid json\n",
    "    val = list(jso.values())[0]\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637a5e8-c892-467e-b6c9-aeaaf0760e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving agreements to disk\n",
    "data_dir = \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd267cc-521f-4a9a-a069-8de97cb41492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for line count\n",
    "def get_line_count(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        num_lines = sum(1 for _ in f)\n",
    "    return num_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30434ded-d161-4123-9ba9-7a1b1228d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet saving function - will automatically chunk saved information into files\n",
    "def save_snippet(sni, name, max_entries_per_file=1000):\n",
    "    # Make a DataFrame with the new piece of information\n",
    "    df = pd.DataFrame([sni])\n",
    "\n",
    "    # Make destination directory\n",
    "    directory = os.path.join(data_dir, name)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Inspect already present files\n",
    "    found_files = sorted(glob(os.path.join(directory, \"*.csv\")))\n",
    "    if len(found_files) > 0:\n",
    "        # Find out ID of last file\n",
    "        last_path = found_files[-1]\n",
    "        last_filename = os.path.split(last_path)[-1]\n",
    "        last_filename = os.path.splitext(last_filename)[0]\n",
    "        file_id = int(last_filename.split(\"_\")[-1])\n",
    "\n",
    "        # Find out its number of entries\n",
    "        num_entries = get_line_count(last_path) - 1\n",
    "        if num_entries >= max_entries_per_file:\n",
    "            # Create a new file\n",
    "            file_id += 1\n",
    "        else:\n",
    "            # Load the file and append to it\n",
    "            df_old = pd.read_csv(last_path)\n",
    "            df = pd.concat([df_old, df])\n",
    "    else:\n",
    "        file_id = 0\n",
    "\n",
    "    # Save file\n",
    "    filename = f\"{name}_{file_id:06d}.csv\"\n",
    "    df.to_csv(os.path.join(directory, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68a250-d08c-4fb9-866c-7ab6825e86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full process of agreement check\n",
    "def do_statements_agree(video_info, statement_1, statement_2, verbose=False):\n",
    "    # Make prompt\n",
    "    prompt = build_prompt_do_statements_agree(video_info, statement_1, statement_2)\n",
    "\n",
    "    # Send prompt to LLM\n",
    "    res_raw = llm.chat(prompt)\n",
    "    if verbose:\n",
    "        print(f\"Raw LLM response: {res_raw}\")\n",
    "    rating = post_process_single_entry_json(res_raw)\n",
    "\n",
    "    # Save this snippet of information to a file\n",
    "    save_snippet(\n",
    "        {\n",
    "            \"statement_1\": statement_1,\n",
    "            \"statement_2\": statement_2,\n",
    "            \"video_title\": get_title(video_info),\n",
    "            \"agreement_rating\": rating\n",
    "        },\n",
    "        \"agreements\"\n",
    "    )\n",
    "\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac23e9-6b68-4fd7-9e2a-ad66329d7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top k comments, according to likes\n",
    "k = 2\n",
    "comments_topk = sorted(comments, key=lambda comm: comm.likes, reverse=True)[:k]\n",
    "comments_topk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b791e9c-ed3d-4f84-8734-c9993a0432b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_positive = \"agree\"\n",
    "agreement_neutral = \"neutral\"\n",
    "agreement_negative = \"disagree\"\n",
    "agreements_nonneutral = [agreement_positive, agreement_negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74724498-d4a0-4628-aa03-27a63f5c014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement_scores_raw = defaultdict(list)\n",
    "statement_agreements_raw = defaultdict(dict)\n",
    "\n",
    "statements = sum(comment_statements.values(), [])  # get all statements, regardless of kind\n",
    "comparisons_all = list(itertools.product(statements, comments_topk))\n",
    "for statement, comment in tqdm(comparisons_all, desc=\"Measuring statement agreement with comments ...\"):\n",
    "    # Find out agreement between statement and comment\n",
    "    agreement = do_statements_agree(\n",
    "        video_info=info,\n",
    "        statement_1=statement,\n",
    "        statement_2=comment.text\n",
    "    )\n",
    "\n",
    "    # Calculate agreement score\n",
    "    likes = comment.likes\n",
    "    score = agreement * likes\n",
    "\n",
    "    # Add measured score to the statement's score\n",
    "    statement_scores_raw[statement].append(score)\n",
    "\n",
    "    # Add likes to agreement class\n",
    "    agreement_class = agreement_positive if agreement > 0 else (agreement_negative if agreement < 0 else agreement_neutral)\n",
    "    tally = statement_agreements_raw[statement]\n",
    "    if agreement_class not in tally:\n",
    "        tally[agreement_class] = []\n",
    "    tally[agreement_class].append(likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0b628-8d76-4ee2-a14a-a0020ea003c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total like count to \"normalize\" scores\n",
    "total_likes = np.sum([comm.likes for comm in comments_topk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118b896-331a-4f92-9126-79417133ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize scores by using total like count\n",
    "statement_scores_norm = {statement: [s / total_likes for s in scores] for (statement, scores) in statement_scores_raw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4f249-5437-422a-9cd4-dda419e1ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum agreements to get scores\n",
    "statement_scores_total = {statement: np.sum(scores) for (statement, scores) in statement_scores_norm.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50445c3f-9a10-4c4e-9079-bb65a8c13b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for statement, score in statement_scores_total.items():\n",
    "    print(f\"Statement '{statement}'\".ljust(15 + max(len(s) for s in statements)) + f\"->\" + f\"{score:0.2f}\".rjust(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bc2a8-85c9-4400-a730-cf1f2c689e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the fraction of comments (weighted by likes) that agree, are neutral, or disagree\n",
    "statement_agreements_norm = {statement: {opinion: sum(likes) / total_likes for (opinion, likes) in agree_info.items()} for (statement, agree_info) in statement_agreements_raw.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e37456-5748-41cd-a726-729b02319148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for statement, agree_info in statement_agreements_norm.items():\n",
    "    # Remove neutral votes (but remember them)\n",
    "    frac_neutral = agree_info.get(agreement_neutral, 0)\n",
    "    frac_engaged = 1 - frac_neutral\n",
    "\n",
    "    # Re-normalize other votes\n",
    "    if frac_neutral > 0:\n",
    "        prob_mass = sum(agree_info.get(opinion, 0) for opinion in agreements_nonneutral)\n",
    "        agree_info = {opinion: frac / prob_mass for (opinion, frac) in agree_info.items()}\n",
    "\n",
    "    # Sort opinions alphabetically and keep only non-neutral opinions\n",
    "    agree_info = sorted(agree_info.items(), key=lambda t: t[0])\n",
    "    agree_info = [(opinion, fraction) for (opinion, fraction) in agree_info if opinion in agreements_nonneutral]\n",
    "\n",
    "    # Format everything\n",
    "    statement_str = f\"Statement '{statement}'\".ljust(15 + max(len(s) for s in statements))\n",
    "    if frac_engaged > 0:\n",
    "        engagement_str = f\"{100 * frac_engaged:0.2f}% are discussing this, out of those \"\n",
    "        opinion_str = \", \".join(f\"{100 * fraction:0.0f}% {opinion}\" for (opinion, fraction) in agree_info).center(24)\n",
    "        discussion_str = engagement_str + opinion_str\n",
    "    else:\n",
    "        discussion_str = \"No comments (of those checked) are discussing this.\"\n",
    "    \n",
    "    print(statement_str + f\"->  \" + discussion_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a38b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52180ef6-3130-4cf7-a50e-c90492468cb1",
   "metadata": {},
   "source": [
    "## Embedding and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafec46a-adaf-4edd-9ac8-e5b4b8622d22",
   "metadata": {},
   "source": [
    "Here, our goal is to find out trends or common themes in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab31c-4d4b-4d1f-87f6-454d5e024638",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_for_clustering = flatten_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e942ad-f8e5-4cfe-af8a-89c7102997b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vecs = []\n",
    "for comm in tqdm(comments_for_clustering, desc=\"Calculating embeddings ...\"):\n",
    "    emb_vecs.append(comm.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f790aa5-53f9-4b50-be56-0de9d7b47d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.stack(emb_vecs)\n",
    "emb_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ded057-e3fb-471c-9878-cdb73980b04b",
   "metadata": {},
   "source": [
    "Let's cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911c81a-045c-4ae7-b2d9-700fce0d785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmeans(matrix, n=5):\n",
    "    clustering_method = KMeans(n_clusters=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc172c-5b51-4094-91c3-1f2b815a67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_spectral_clustering(matrix, n=5):\n",
    "    clustering_method = SpectralClustering(n_clusters=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401638a0-2533-462b-b211-7e7802dc95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_dbscan(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = DBSCAN()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75efb2-7c26-4e4e-9fd8-298cc80a0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_optics(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = OPTICS()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f023f51-c432-4fd8-925a-5249d8fb0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hdbscan(matrix, n=5):\n",
    "    # argument `n` is ignored\n",
    "    clustering_method = HDBSCAN()\n",
    "    clustering_method.fit(matrix)\n",
    "    return clustering_method.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678f98a-5ec4-4508-8a22-b9d80b39b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(matrix, n=5):\n",
    "    clustering_method = GaussianMixture(n_components=n)\n",
    "    clustering_method.fit(matrix)\n",
    "    labels = clustering_method.predict(matrix)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c965090-39c5-48b4-af63-fb3b9cc04060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_clustering(matrix, labels):\n",
    "    labs_unique = list(np.unique(labels))\n",
    "    \n",
    "    # Silhouette score for each sample (i.e., comment)\n",
    "    try:\n",
    "        sil_all = silhouette_samples(matrix, labels)\n",
    "    except ValueError:\n",
    "        # this may happen if there is only one label\n",
    "        sil_all = np.copy(labels)\n",
    "        sil_all.fill(-1)  # worst possible value\n",
    "    \n",
    "    # Silhouette score, aggregated by cluster\n",
    "    sil_for_labels = [np.mean(sil_all[np.where(labels == lab)[0]]) for lab in labs_unique]\n",
    "    \n",
    "    return labs_unique, sil_for_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb495a67-8fd8-4243-8067-f8957bb7a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterings = []\n",
    "n_range = [2, 3, 4, 5, 6, 7, 8, 16, 32, 64]\n",
    "clus_funs = [cluster_kmeans, cluster_gmm, cluster_spectral_clustering, cluster_hdbscan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29c632-cb05-4ab9-ad9a-6eac2dd7fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, clus_fun in tqdm(list(itertools.product(n_range, clus_funs)), desc=\"Clustering ...\"):\n",
    "    # Cluster\n",
    "    labels = clus_fun(emb_matrix, n=n)\n",
    "\n",
    "    # Evaluate\n",
    "    labs_unique, sil_for_labels = eval_clustering(emb_matrix, labels)\n",
    "    \n",
    "    clusterings.append((labels, labs_unique, sil_for_labels, n, clus_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d59ba1-ec03-46af-88bc-31af13440362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove clustering if it is degenerate (i.e., the majority of points are in a single cluster)\n",
    "cluster_sizes = [[len(np.where(labels == lab)[0]) / len(labels) for lab in labs_unique] for (labels, labs_unique, _, _, _) in clusterings]\n",
    "cluster_sizes = [(idx, si, min(2 / len(si), 0.8)) for (idx, si) in enumerate(cluster_sizes)]\n",
    "legal_indices = [idx for (idx, si, limit) in cluster_sizes if (max(si) <= limit)]\n",
    "clusterings = [clusterings[idx] for idx in legal_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f7405-5336-4c58-8b07-ce5a37590c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"After filtering out degenerate clusterings, proceeding with {len(clusterings)} clusterings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36d705-15d0-482c-9192-e32c765e4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by mean of Silhouette coefficient: largest first\n",
    "clusterings.sort(key=lambda t: np.mean(t[2]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bbe85-020d-47c7-92d8-91837321d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best clustering\n",
    "labels, labs_unique, sil_for_labels, n, clus_fun = clusterings[0]\n",
    "print(f\"Best clustering out of {len(clusterings)} is with n = {n}, with a mean Silhouette coefficient of {np.mean(sil_for_labels):0.8f} (function was {clus_fun}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede85cc1-a251-4c31-9275-c80df6c38c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare colormap for plotting\n",
    "cm_steps = len(labs_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e35e93-a602-4800-879a-8fefd23627cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = mpl.colormaps.get_cmap('hsv')\n",
    "cmap = mpl.colors.ListedColormap(hsv(np.linspace(0,1,cm_steps + 1)[:-1]))\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d5e5d-665c-4a91-80d0-7f65489252aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_for_idx(idx, colormap):\n",
    "    return colormap.colors[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ee829-c412-4839-b9b6-15371dbba51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_for_label(label, labels_unique, colormap):\n",
    "    idx = labels_unique.index(label)\n",
    "    return color_for_idx(idx, colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f117801-60a8-4de7-9bcc-4d37f9ae56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(matrix, labels_unique, labels, use_umap=True):\n",
    "    if use_umap:\n",
    "        # Use UMAP\n",
    "        reducer = umap.UMAP()\n",
    "    else:\n",
    "        # Use t-SNE\n",
    "        reducer = TSNE(\n",
    "            n_components=2,\n",
    "            learning_rate='auto',\n",
    "            init='random',\n",
    "            perplexity=3\n",
    "        )\n",
    "\n",
    "    # Fit\n",
    "    matrix_2d = reducer.fit_transform(matrix)\n",
    "\n",
    "    # Plot\n",
    "    plt.scatter(x=matrix_2d[:, 0], y=matrix_2d[:, 1], c=[color_for_label(lab, labels_unique, cmap) for lab in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67228b73-7cf2-443a-ac6f-2b7488392ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(emb_matrix, labs_unique, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dacae4-2712-43da-855a-45591b669712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_find_topic(video_info, comments: List[Comment]):\n",
    "    title = get_title(video_info)\n",
    "    lines = [f\"You are a professional YouTube comment analyst. Given a video title and some comments, find the topic of the comments.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    \n",
    "    lines.append(\"\\nSample from the comments:\")\n",
    "    comm_lines = sample_from_comments(comments)\n",
    "    lines += comm_lines\n",
    "\n",
    "    lines.append(\"\\nExtract a single, coherent topic that these comments are discussing. The topic you find can also be about the style or mood of the comments. \" \\\n",
    "                 \"A topic should be a simple notion, e.g., \\\"Jokes\\\" or \\\"Choosing a keyboard\\\".\" \\\n",
    "                 \"There is no need to repeat the video title in your assessment. The topic should also describe what the comments are saying, so it shouldn't be, e.g., \\\"Reactions to Video\\\" or anything generic of that sort. Provide your assessment in the form of JSON such as {\\\"topic\\\": your_topic_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9310abe-a5a5-4fff-85ff-fbac915643a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "divider_width = 100\n",
    "divider_str = \"-\"\n",
    "show_random_comments = False\n",
    "cluster_topics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da8e59-9513-403c-a651-d30480fd71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_clusters():\n",
    "    for lab in labs_unique:\n",
    "        print(f\"Cluster Description (Label {lab})\".center(divider_width, divider_str))\n",
    "    \n",
    "        # Size\n",
    "        cluster_size = sum(labels == lab)\n",
    "        print(f\"- Cluster size: {cluster_size} ({100 * cluster_size / len(labels):0.2f}%)\")\n",
    "    \n",
    "        # Get indices\n",
    "        clus_indices = np.where(labels == lab)[0]\n",
    "        \n",
    "        # Find mean embedding of cluster\n",
    "        clus_mean_emb = np.mean(np.stack([emb_matrix[idx] for idx in clus_indices]), axis=0)\n",
    "        \n",
    "        # Sort comments by distance to mean embedding\n",
    "        clus_comments = [comments_for_clustering[idx] for idx in clus_indices]\n",
    "        clus_comments.sort(key=lambda comment: np.sum(np.abs(comment.get_embedding()) - clus_mean_emb))\n",
    "    \n",
    "        # Find out central topic of cluster\n",
    "        if lab not in cluster_topics:\n",
    "            clus_comments_central = clus_comments[:1000]\n",
    "            prompt = build_prompt_find_topic(info, clus_comments_central)\n",
    "            res_raw = llm.chat(prompt)\n",
    "            topic = post_process_single_entry_json(res_raw)\n",
    "            cluster_topics[lab] = topic\n",
    "        print(f\"- Central topic (LLM): {cluster_topics[lab]}\")\n",
    "    \n",
    "        # Show comment closest to the mean\n",
    "        print(\"- Comment closest to mean embedding:\")\n",
    "        print(clus_comments[0])\n",
    "    \n",
    "        # Show random comments\n",
    "        if show_random_comments:\n",
    "            rnd_indices = np.random.choice(clus_indices, size=min(5, cluster_size), replace=False)\n",
    "            print()\n",
    "            print(f\"- {len(rnd_indices)} random comments from this cluster: \")\n",
    "            for idx in rnd_indices:\n",
    "                print(f\"- {comments_for_clustering[idx]}\")\n",
    "    \n",
    "        print(\"\".center(divider_width, divider_str))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca511d-5bf3-477e-b0f4-cc7f8d0d0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31618677-8090-4f2d-8eb9-5759562a374c",
   "metadata": {},
   "source": [
    "### Fuse clusters based on topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047eb02-ad8e-4014-877c-5974b0c244cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_groups = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb239f-e256-4248-90b0-1b25b4248aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab, topic in cluster_topics.items():\n",
    "    # Store this cluster label and topic as a tuple\n",
    "    tup = (lab, topic)\n",
    "    \n",
    "    # Try to find a spot for this topic in one of the groups\n",
    "    found_group = False\n",
    "    for group in cluster_groups:\n",
    "\n",
    "        # If the group is empty, add the cluster (this only happens at the beginning)\n",
    "        if len(group) == 0:\n",
    "            group.append(tup)\n",
    "            found_group = True\n",
    "            break\n",
    "\n",
    "        # Compare this cluster's embedding with the group\n",
    "        mean_sim = np.mean([cos_sim(text_model_manager.embed(top), text_model_manager.embed(topic)) for (l, top) in group])\n",
    "        if mean_sim > 0.55:\n",
    "            group.append(tup)\n",
    "            found_group = True\n",
    "            break\n",
    "\n",
    "    # If we already found a group, go on to the next cluster's topic\n",
    "    if found_group:\n",
    "        continue\n",
    "\n",
    "    # Start a new group\n",
    "    cluster_groups.append([tup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb0ad4-8188-4215-8f5b-100bbee4023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_fuse_topics(video_info, topics: List[str]):\n",
    "    title = get_title(video_info)\n",
    "    lines = [f\"You are a professional YouTube comment analyst. Given a video title and some comment topics, find a new description of the topic that reflects the core concept of the listed topics.\"]\n",
    "    lines.append(f\"Video title: {title}\")\n",
    "    \n",
    "    lines.append(\"\\nComment topics:\")\n",
    "    lines += [f\"- {t}\" for t in topics]\n",
    "\n",
    "    lines.append(\"\\nExtract a single, coherent topic that describes all these topics. The topic you find can also be about the style or mood of the comments. \" \\\n",
    "                 \"A topic should be a simple notion, e.g., \\\"Jokes\\\" or \\\"Choosing a keyboard\\\".\" \\\n",
    "                 \"There is no need to repeat the video title in your assessment. The topic shouldn't be, e.g., \\\"Reactions to Video\\\" or anything generic of that sort. Provide your assessment in the form of JSON such as {\\\"topic\\\": your_topic_goes_here}.\")\n",
    "\n",
    "    prompt = \"\\n\".join(lines)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7971b2-6e07-4392-a128-440611be1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse groups we found by finding a new topic\n",
    "fused_groups = []\n",
    "for group in tqdm(cluster_groups, desc=\"Fusing groups ...\"):\n",
    "    labs, topics = zip(*group)\n",
    "\n",
    "    if len(topics) > 1:\n",
    "        prompt = build_prompt_fuse_topics(info, topics)\n",
    "        res_raw = llm.chat(prompt)\n",
    "        topic = post_process_single_entry_json(res_raw)\n",
    "    else:\n",
    "        topic = topics[0]\n",
    "\n",
    "    fused_groups.append((labs, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225976d-8fc4-4e7b-a50b-d4cabe2aee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labeling of clustering to reflect group fusions\n",
    "for label_group, topic in fused_groups:\n",
    "    # No need to change any labels if we \"group\" doesn't have multiple labels\n",
    "    if len(label_group) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Paint all labels in group to match the first label\n",
    "    label_group = list(label_group)\n",
    "    lab_first = label_group.pop(0)\n",
    "    for lab in label_group:\n",
    "        labels[np.where(labels == lab)] = lab_first\n",
    "\n",
    "    # Remember topic\n",
    "    cluster_topics[lab_first] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39160f07-4b5f-4ea0-9c77-302d7fd3e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_unique = list(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411dcbe-0337-48ae-bb01-047ba031f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(emb_matrix, labs_unique, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf6ac1-d320-4a48-9ba2-0a8e53c145ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e000da",
   "metadata": {},
   "source": [
    "## Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_analyzer = ClassificationAnalyzer(comments)\n",
    "print(classification_analyzer.run_all_analyses())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_comments",
   "language": "python",
   "name": "yt_comments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
